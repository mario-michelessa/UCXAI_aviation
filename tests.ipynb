{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coverage(seeds, suffix = 'seeds') : \n",
    "    \n",
    "    splits_greedy = []\n",
    "    for i, edge in enumerate(g_instance.edges()) :\n",
    "        if edge[0] in seeds : \n",
    "            splits_greedy.append(i)\n",
    "    is_greedy = []\n",
    "    for i in range(len(splits_greedy)):\n",
    "        is_greedy += list(range(splits[splits_greedy[i]], splits[splits_greedy[i]+1]))\n",
    "    bundle_curves_greedy = bundle_curves[bundle_curves.index.isin(is_greedy)]\n",
    "    bundle_curves_other = bundle_curves[~bundle_curves.index.isin(is_greedy)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.plot(bundle_curves_other.x, bundle_curves_other.y, '#1868AD', zorder=1, linewidth=0.5, alpha = 0.6)\n",
    "    ax.plot(bundle_curves_greedy.x, bundle_curves_greedy.y, '#E1341E', zorder=1, linewidth=0.5, alpha = 0.6)\n",
    "    ax.set_title(f\"Coverage of {len(seeds)} seeds by the greedy algorithm\")\n",
    "    fig.savefig(f'./graph_viz/coverage/{len(seeds)}_{suffix}.png')\n",
    "    plt.close(fig)\n",
    "\n",
    "# for c in range(20): \n",
    "#     print(c)\n",
    "#     print_coverage(seeds_20[:c], suffix = '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = torch.load('./weibo/model_df.pt', map_location=torch.device('cpu'))\n",
    "Ydf = model_df(torch.from_numpy(X).float()).view_as(torch.from_numpy(Y)).detach()\n",
    "df_seeds = greedy2(20, Ydf)\n",
    "\n",
    "# c = 0\n",
    "# for c in range(20): \n",
    "#     print(c)\n",
    "#     print_coverage(df_seeds[:c], suffix = 'df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "model_2s = torch.load('./results/24-150cas/net_2s_20_5_db_0.pt', map_location=torch.device('cpu'))\n",
    "Y2s = model_2s(torch.from_numpy(X).float()).view_as(torch.from_numpy(Y)).detach()\n",
    "twos_seeds = greedy2(20, Y2s)\n",
    "\n",
    "c = 0\n",
    "for c in range(20): \n",
    "    print(c)\n",
    "    print_coverage(twos_seeds[:c], suffix = '2s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do the same for label_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# model_df = torch.load('./results/24-150cas/net_df_20_5_db_0.pt', map_location=torch.device('cpu'))\n",
    "# model_2s = torch.load('./results/24-150cas/net_2s_20_5_db_0.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "label_sparse = pd.read_pickle('data/weibo_preprocessed/labels1_5K_10.pkl')\n",
    "\n",
    "# edge_sparse = pd.read_pickle('data/weibo_preprocessed/edges1_5K_10.pkl')\n",
    "# d_edge = defaultdict(lambda : 0)\n",
    "# for (u,v) in zip(edge_sparse['u'], edge_sparse['v']) : d_edge[(u,v)] = 1\n",
    "\n",
    "fi = pd.read_pickle('./data/weibo_features/features_influencers1_5K_10_cas.pkl')\n",
    "ft = pd.read_pickle('./data/weibo_features/features_targets1_5K_10_cas.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3154 36375\n"
     ]
    }
   ],
   "source": [
    "influencers = list(label_sparse.groupby('u').count().index.intersection(fi.index))\n",
    "targets = list(label_sparse.groupby('v').count().index.intersection(ft.index))\n",
    "nI = len(influencers)\n",
    "nT = len(targets)\n",
    "print(nI, nT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to generate Ydf and Y2s\n",
    "# nChunkI = 6\n",
    "# nChunkT = 50\n",
    "# for c, chunk_i in enumerate(np.array_split(fi, nChunkI)) : \n",
    "#     print(c)\n",
    "#     size_i = len(chunk_i)\n",
    "#     lines_df = np.zeros((size_i, nT))\n",
    "#     lines_2s = np.zeros((size_i, nT))\n",
    "#     end = 0\n",
    "#     for d, chunk_j in enumerate(np.array_split(ft, nChunkT)) :\n",
    "#         size_t = len(chunk_j)\n",
    "#         f1 = np.array(chunk_i) #size i x 24\n",
    "#         f2 = np.array(chunk_j) #size t x 24\n",
    "#         feature_matrix = np.concatenate([ np.tile(np.array(f1).reshape((f1.shape[0], 1, f1.shape[1])), (1,f2.shape[0],1)), np.tile(np.array(f2).reshape((1, f2.shape[0],f2.shape[1])), (f1.shape[0], 1, 1))], axis=2)\n",
    "#         adj_edge = np.zeros((size_i, size_t, 1))\n",
    "#         for i, u in enumerate(chunk_i.index) :\n",
    "#             for j, v in enumerate(chunk_j.index) : \n",
    "#                 adj_edge[i,j,0] = d_edge[(u,v)]\n",
    "#         feature_matrix = torch.from_numpy(np.concatenate([feature_matrix, adj_edge], axis = 2)).float()\n",
    "#         lines_df[:, end:  min(end + size_t, nT)] = model_df(feature_matrix).detach().numpy()[:,:,0]\n",
    "#         lines_2s[:, end:  min(end + size_t, nT)] = model_2s(feature_matrix).detach().numpy()[:,:,0]\n",
    "#         end += size_t\n",
    "#     np.save(f'./results/graph_viz/sparse/Ydf_{c}.npy', lines_df)\n",
    "#     np.save(f'./results/graph_viz/sparse/Y2s_{c}.npy', lines_2s)\n",
    "\n",
    "# Ydf = np.load(f'./results/graph_viz/sparse/Ydf_{0}.npy')\n",
    "# for i in range(1,6) : \n",
    "#     Ydf = np.concatenate([Ydf, np.load(f'./results/graph_viz/sparse/Ydf_{i}.npy')], axis=0)\n",
    "\n",
    "# np.save(f'./results/graph_viz/sparse/Ydf.npy', Ydf)\n",
    "\n",
    "# Y2s = np.load(f'./results/graph_viz/sparse/Y2s_{0}.npy')\n",
    "# for i in range(1,6) : \n",
    "#     Y2s = np.concatenate([Y2s, np.load(f'./results/graph_viz/sparse/Y2s_{i}.npy')], axis=0)\n",
    "\n",
    "# np.save(f'./results/graph_viz/sparse/Y2s.npy', Y2s)\n",
    "\n",
    "# Yds = np.zeros((nI, nT))\n",
    "# for k, row in label_sparse.iterrows() : \n",
    "#     try : \n",
    "#         i = influencers.index(int(row.u))\n",
    "#         j = targets.index(int(row.v))\n",
    "#         Yds[i, j] = row['JI'] \n",
    "#     except : \n",
    "#         pass\n",
    "# np.save('./results/graph_viz/sparse/Yds.npy', Yds)\n",
    "\n",
    "# Ydf = np.load('./results/graph_viz/sparse/Ydf.npy')\n",
    "# Y2s = np.load('./results/graph_viz/sparse/Y2s.npy')\n",
    "# Yds = np.load('./results/graph_viz/sparse/Yds.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_func(S, P):\n",
    "#     s = torch.zeros(P.shape[0])\n",
    "#     s[S] = 1\n",
    "#     return float(torch.sum(1 - torch.prod(1 - (s*P.T).T, axis = 0)))\n",
    "\n",
    "# def marginal_vec(S, P):\n",
    "#     s = torch.zeros(P.shape[0])\n",
    "#     s[S] = torch.ones(len(S))\n",
    "#     sc = torch.ones_like(s) - s\n",
    "#     return sc * torch.mv(P, torch.prod(1 - (s*P.T).T, axis = 0))\n",
    " \n",
    "# def greedy2(K, P):\n",
    "#     S = []\n",
    "#     for i in range(K):\n",
    "#         g = marginal_vec(S, P)\n",
    "#         s = int(torch.argmax(g))\n",
    "#         if s not in S: \n",
    "#             S += [s]\n",
    "#     return S\n",
    "\n",
    "# greedy_seeds_df = greedy2(150, torch.from_numpy(Ydf).float())\n",
    "# greedy_seeds_2s = greedy2(150, torch.from_numpy(Y2s).float())\n",
    "# greedy_seeds_ds = greedy2(150, torch.from_numpy(Yds).float())\n",
    "\n",
    "# with open('./results/graph_viz/sparse/greedy_seeds_df.txt', 'w') as f:\n",
    "#     for item in greedy_seeds_df:\n",
    "#         f.write(str(item))\n",
    "\n",
    "# with open('./results/graph_viz/sparse/greedy_seeds_2s.txt', 'w') as f:\n",
    "#     for item in greedy_seeds_2s:\n",
    "#         f.write(str(item))\n",
    "\n",
    "# with open('./results/graph_viz/sparse/greedy_seeds_ds.txt', 'w') as f:\n",
    "#     for item in greedy_seeds_ds:\n",
    "#         f.write(str(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "g_sparse = nx.DiGraph()\n",
    "g_sparse.add_nodes_from(influencers)\n",
    "g_sparse.add_nodes_from(targets)\n",
    "for k, row in label_sparse.iterrows() :\n",
    "    g_sparse.add_edge(int(row.u), int(row.v), weight = row['JI'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Error at src/core/vector.c:146: Cannot initialize vector. -- Out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)\n",
      "\u001b[1;32md:\\Mario\\notebooks\\IM_smoothed_greedy\\graph_viz.ipynb Cellule 29\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Mario/notebooks/IM_smoothed_greedy/graph_viz.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m\"\"\" cross edges reduction layout is only available for igraph\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Mario/notebooks/IM_smoothed_greedy/graph_viz.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39migraph\u001b[39;00m \n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Mario/notebooks/IM_smoothed_greedy/graph_viz.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m g_sparse_igraph \u001b[39m=\u001b[39m igraph\u001b[39m.\u001b[39;49mGraph(g_sparse\u001b[39m.\u001b[39;49medges())\n",
      "\n",
      "File \u001b[1;32md:\\0. PROGRAMMES SSD\\Anaconda\\envs\\MLviz\\lib\\site-packages\\igraph\\__init__.py:448\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    446\u001b[0m     GraphBase\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, __ptr\u001b[39m=\u001b[39mptr)\n",
      "\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 448\u001b[0m     GraphBase\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, nverts, edges, directed)\n",
      "\u001b[0;32m    450\u001b[0m \u001b[39m# Set the graph attributes\u001b[39;00m\n",
      "\u001b[0;32m    451\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m graph_attrs\u001b[39m.\u001b[39mitems():\n",
      "\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error at src/core/vector.c:146: Cannot initialize vector. -- Out of memory"
     ]
    }
   ],
   "source": [
    "\"\"\" cross edges reduction layout is only available for igraph\"\"\"\n",
    "import igraph \n",
    "g_sparse_igraph = igraph.Graph(g_sparse.edges())\n",
    "# g_sparse_igraph.simplify()\n",
    "\n",
    "# layout_bi = g_instance_igraph.layout_bipartite(hgap = 1, vgap = 1, maxiter = 100)\n",
    "# layout_bi_df = pd.DataFrame(layout_bi.coords, columns=['x', 'y'])\n",
    "# layout_bi_df.index.name = 'id'\n",
    "# layout_bi_nx = dict({i : np.array([layout_bi_df.loc[i, 'x'], layout_bi_df.loc[i, 'y']]) for i in range(layout_bi_df.shape[0])})\n",
    "# nx.draw(g_instance, pos=layout_bi_nx, node_size=1, edge_color='#888888', width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
